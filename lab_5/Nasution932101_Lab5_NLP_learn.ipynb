{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Learn for LAB 5\n"
      ],
      "metadata": {
        "id": "gNB8ubfIdgc6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PktZoQ-aQq3",
        "outputId": "b03fe913-f860-4402-bc52-27253181d5dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7b221c2d0890>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from sys import argv\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_tokenizer_and_model(model_name_or_path):\n",
        "    return GPT2Tokenizer.from_pretrained(model_name_or_path), GPT2LMHeadModel.from_pretrained(model_name_or_path)\n"
      ],
      "metadata": {
        "id": "Refx4TI1d2Ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(\n",
        "            model, tok, text,\n",
        "            do_sample=True, max_length=100, repetition_penalty=5.0,\n",
        "            top_k=5, top_p=0.95, temperature=1,\n",
        "            num_beams=None,\n",
        "            no_repeat_ngram_size=3\n",
        "            ):\n",
        "          input_ids = tok.encode(text, return_tensors=\"pt\")\n",
        "          print(model.generate.__globals__['__file__'])\n",
        "          out = model.generate(\n",
        "              input_ids,\n",
        "              max_length=max_length,\n",
        "              repetition_penalty=repetition_penalty,\n",
        "              do_sample=do_sample,\n",
        "              top_k=top_k, top_p=top_p, temperature=temperature,\n",
        "              num_beams=num_beams, no_repeat_ngram_size=no_repeat_ngram_size\n",
        "              )\n",
        "          return list(map(tok.decode, out))"
      ],
      "metadata": {
        "id": "1WWkFscQhOmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tok, model = load_tokenizer_and_model('sberbank-ai/rugpt3large_based_on_gpt2')\n",
        "generated = generate(model, tok, argv[1], num_beams=10)\n",
        "\n",
        "print(generated[0])\n",
        "\n",
        "# generator = pipeline('text-generation', model=model, tokenizer=tok)\n",
        "# generated = generator(argv[1], num_beams=10, max_length=100) # Assuming argv[1] contains the prompt\n",
        "\n",
        "# print(generated[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lncr7ZRveZLV",
        "outputId": "f18fc73c-e990-4b7e-c20c-97193197a77c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\n",
            "-family:Calibri;}\n",
            ".MsoChpDefault\n",
            " {mso-style-type:export-only;\n",
            " line-height:115%;\n",
            " mso-pagination:widow-orphan;\n",
            " font-size:11.0pt;\n",
            " padding:2.0cm 42.5pt 2.1cm 3.21cm;\n",
            " text-\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dwE5BhTEeqRK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}